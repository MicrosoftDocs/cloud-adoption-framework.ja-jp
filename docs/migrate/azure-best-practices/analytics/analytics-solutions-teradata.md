---
title: Teradata の分析ソリューション
description: Azure のクラウド導入フレームワークを使用して、Teradata を使用した分析ソリューションについて学習します。
author: v-hanki
ms.author: brblanch
ms.date: 07/14/2019
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: migrate
ms.openlocfilehash: 85dc03afc7ea0d8c931c24009beb220d03b108e5
ms.sourcegitcommit: 9163a60a28ffce78ceb5dc8dc4fa1b83d7f56e6d
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/17/2020
ms.locfileid: "86452659"
---
<!-- cSpell:ignore DATEADD DATEDIFF Attunity Teradata Inmon NUSI Informatica Talend BTEQ FASTEXPORT QUALIFY ORC Parquet "Parallel Data Transporter" "Attunity Replicate" -->

# <a name="analytics-solutions-for-teradata"></a>Teradata の分析ソリューション

Teradata データ ウェアハウス システムの既存のユーザーは、新しい環境 (クラウド、IaaS、PaaS など) によって提供されるイノベーションを利用し、インフラストラクチャのメンテナンスやプラットフォーム開発などのタスクをクラウド プロバイダーに委任することを検討しています。

Teradata と Azure Synapse Analytics には類似点があり、両者とも大規模なデータ量に対して高いクエリ パフォーマンスを実現するために、超並列処理 (MPP) 手法を使用するように設計された SQL データベースです。ただし、アプローチには基本的な違いがいくつかあります。

- レガシ Teradata システムは、通常、独自のハードウェアを使用してオンプレミスにインストールされます。一方、Azure Synapse Analytics では、クラウドベースのストレージとコンピューティング リソースが使用されます。
- Teradata の構成のアップグレードは、物理ハードウェアの追加や、長時間かかる可能性のあるデータベースの再構成を伴う大きなタスクです。 ストレージとコンピューティング リソースは Azure 環境では分離されているため、これらのリソースは、エラスティック スケーラビリティ機能を使用し、独立して容易にスケーリング (アップおよびダウン) できます。
- 必要に応じて、Azure Synapse Analytics を一時停止またはサイズ変更して、リソース使用率とコストを削減することができます。

これらの利点を最大限に利用するには、既存の (または新規の) データとアプリケーションを Azure Synapse Analytics プラットフォームに移行する必要があります。多くの組織では、これには Teradata などのオンプレミスのレガシ プラットフォームからの既存のデータ ウェアハウスの移行が含まれます。 大まかな基本プロセスには、次の手順が含まれます。

<!-- markdownlint-disable MD033 -->

| 準備 | 移行 | 移行後の処理 |
|---|---|---|
| <li> スコープ (移行する対象) を定義する <li> 移行のためのデータとプロセスのインベントリを作成する <li> データ モデルの変更を定義する (ある場合) <li> 使用する適切な Azure (およびサードパーティ) のツールと機能を特定する <li> 新しいプラットフォームのスタッフ トレーニングを早期に実施する <li> Azure のターゲット プラットフォームをセットアップする |  <li> 小規模で簡単なものから始める <li> 可能であれば自動化する <li> Azure の組み込みツールと機能を使用して移行作業を減らす <li> テーブルとビューのメタデータを移行する <li> 維持する履歴データを移行する <li> ストアド プロシージャとビジネス プロセスを移行またはリファクタリングする <li> ETL/ELT の段階的読み込みプロセスを移行またはリファクタリングする |  <li> プロセスのすべてのステージを監視してドキュメント化する <li> 今後の移行のため、得られた経験を利用してテンプレートを作成する <li> 必要な場合、新しいプラットフォームのパフォーマンスとスケーラビリティを使用して、データ モデルを再エンジニアリングする <li> アプリケーションとクエリ ツールをテストする <li> クエリ パフォーマンスのベンチマークと最適化を行う |

## <a name="migration-scope"></a>移行のスコープ

### <a name="choose-the-workload-for-the-initial-migration"></a>初期移行のワークロードを選択する

レガシ Teradata 環境は、通常、複数の主題領域と混合ワークロードを含むように、時間の経過と共に進化しています。 最初の移行プロジェクトをどこから始めるか決定するときは、次のことが可能な領域を選択する必要があります。

- 新しい環境の利点を迅速に提供することで、Azure Synapse Analytics への移行の実現可能性を証明する。
- 社内のテクニカル スタッフが、他の領域の移行に使用できるプロセスおよびツールの重要な体験を得られるようにする。
- 移行の演習をさらに行うために、ソース Teradata 環境と既に配置済みの現在のツールおよびプロセスに固有のテンプレートを作成する。

上記の事項を可能にする Teradata 環境からの初期移行に適した候補は、通常、BI および分析ワークロード (つまり、OLTP ワークロードではなく) を実装するもので、最小限の変更で移行できるデータ モデル (通常は開始スキーマまたはスノーフレーク スキーマ) を使用するものです。

サイズに関しては、最初の演習で移行するデータ量が、Azure Synapse Analytics 環境の機能と利点を示すのに十分な大きさであることが重要であるとともに、価値を示す時間を短く抑える (通常は 1～10 TB の範囲) 必要があります。

初期移行プロジェクトでリスクを最小化し、初期プロジェクトの実装時間を短縮する方法の 1 つとして、移行のスコープをデータ マートのみに限定することが挙げられます (たとえば、Teradata ウェアハウスの OLAP データベース部分)。 このアプローチでは、定義上、移行のスコープが制限され、通常は短いタイムスケール内で実現できるため、出発点として適している可能性があります。 ただし、このアプローチは、初期移行プロジェクトの一環としての ETL の移行や履歴データの移行など、より広範なトピックには対応していません。 これらには、プロジェクトの後の段階で、移行されたデータ マート レイヤーがそれらを構築するために必要なデータとプロセスでバック フィルされたときに、対処する必要があります。

## <a name="lift-and-shift-as-is-versus-a-phased-approach-incorporating-changes"></a>そのままでのリフト アンド シフトと、変更を伴う段階的なアプローチ

目的の移行のドライバーやスコープにかかわらず、一般に次の 2 種類の移行があります。

### <a name="lift-and-shift"></a>リフト アンド シフト

この場合、既存のデータ モデル (スター スキーマなど) は、そのまま新しい Azure Synapse Analytics プラットフォームに移行されます。 ここで重視される点は、Azure クラウド環境への移行の利点を実現するために必要な作業を減らすことで、リスクを最小限に抑え、移行にかかる時間を短縮することです。

これは、1 つのデータ マートが移行される既存の Teradata 環境に適しています。または、適切に設計されたスター スキーマまたはスノーフレーク スキーマにデータが既に含まれている場合や、最新の環境に移行するための時間のプレッシャーがある場合におそらく適しています。

### <a name="phased-approach-incorporating-modifications"></a>変更を伴う段階的なアプローチ

レガシ ウェアハウスが長い間に進化している場合は、必要なパフォーマンスレベルを維持したり、新しいデータ (IoT ストリームなど) をサポートしたりするために、再エンジニアリングが必要になる場合があります。 リエンジニアリング プロセスの一環として、スケーラブルなクラウド環境のメリットを利用するために、Azure Synapse Analytics への移行を検討する場合があります。 これには、基になるデータ モデルの変更 (たとえば、Inmon モデルからデータ コンテナーへの移動) が含まれることがあります。

そのためには、最初に既存のデータ モデルをそのまま Azure 環境に移動し (後で説明するように、必要に応じて、Azure で VM Teradata インスタンスを使用します)、Azure 環境のパフォーマンスと柔軟性を使用することをお勧めします。適切であれば、Azure の機能を使用して、既存のソース システムに影響を与えずに変更を行います。

## <a name="using-a-vm-teradata-instance-as-part-of-a-migration"></a>移行の一環としての VM Teradata インスタンスの使用

オンプレミスの Teradata 環境からの移行を実行するためのオプションの 1 つの方法は、安価なクラウド ストレージと柔軟なスケーラビリティが提供される Azure 環境を使用して、Azure の VM 内に Teradata インスタンスを作成し、ターゲットの Azure Synapse Analytics 環境と共存させることです。

このアプローチでは、Teradata Parallel Data Transporter などの標準 Teradata ユーティリティ (または、Attunity Replicate などのサードパーティ製データ レプリケーション ツール) を使用して、VM インスタンスに移行される Teradata テーブルのサブセットを効率的に移動した後、Azure 環境内ですべての移行タスクを実行することができます。 この方法には、いくつかの利点があります。

- データの初期レプリケーションの後、ソース システムは移行タスクの影響を受けません。
- 使い慣れた Teradata のインターフェイス、ツール、ユーティリティを、Azure 環境内で利用できます。
- いったん Azure 環境に移動してしまえば、オンプレミスのソース システムとクラウド ターゲット システムの間で利用可能なネットワーク帯域幅に関する問題が発生する可能性はありません。
- Azure Data Factory などのツールを使用すると、Teradata Parallel Transporter などのユーティリティを効率的に呼び出して、データをすばやく簡単に移行できます。
- 移行プロセスは、Azure 環境内で完全に調整および制御されます。

## <a name="use-azure-data-factory-to-implement-a-metadata-driven-migration"></a>Azure Data Factory を使用してメタデータに基づく移行を実装する

Azure 環境で機能を利用することで、移行プロセスを自動化し、調整することは理にかなっています。 このアプローチにより、既存の Teradata 環境への影響も最小限に抑えられます (既に全容量に近い状態で実行されている可能性があります)。

Azure Data Factory は、データドリブン型のワークフローをクラウドに作成することでデータの移動と変換を制御し、自動化することができるクラウドベースのデータ統合サービスです。 Azure Data Factory を使えば、各種のデータ ストアからデータを取り込むことができるデータ主導型のワークフロー (パイプライン) を作成し、スケジューリングできます。 そのデータは、Azure HDInsight Hadoop、Spark、Azure Data Lake Analytics、Azure Machine Learning などのコンピューティング サービスを使って処理し、変換することができます。

移行するデータ テーブルとその場所をリストするメタデータを作成することにより、Azure Data Factory の機能を使用して移行プロセスの各部分を管理および自動化できます。

## <a name="design-differences-between-teradata-and-azure-synapse-analytics"></a>Teradata と Azure Synapse Analytics の設計の違い

### <a name="separate-databases-versus-schemas"></a>データベースの分離とスキーマの分離

Teradata 環境では、環境全体の個々の部分に対して、複数の個別のデータベースを定義するのが一般的です。たとえば、データ インジェストとステージングのテーブル用のデータベース、コア ウェアハウス テーブル用のデータベース、およびデータ マート用のデータベース (セマンティック レイヤーと呼ばれることもあります) が、個別の存在する場合があります。 ETL/ELT パイプラインなどの処理では、複数データベースにまたがる結合が実装され、これらの個別のデータベース間でデータが移動されます。

Azure Synapse Analytics 環境には 1 つのデータベースがあり、スキーマを使用して、テーブルが論理的に分離されたグループに分割されます。 したがって、Teradata 環境から移行される個別のデータベースを模倣するために、ターゲットの Azure Synapse Analytics 内で一連のスキーマを使用することをお勧めします。 Teradata 環境内でスキーマが使用されている場合は、新しい名前付け規則を使用して、既存の Teradata テーブルおよびビューを新しい環境に移動する必要があります (既存の Teradata スキーマおよびテーブル名を新しい Azure Synapse Analytics テーブル名に連結する、新しい環境でスキーマ名を使用して元の個別のデータベース名を維持するなど)。 もう 1 つの方法は、基になるテーブルに SQL ビューを使用して論理構造を維持することですが、この方法には潜在的な欠点がいくつかあります。

- Azure Synapse Analytics のビューは読み取り専用であるため、データの更新は、基になるベース テーブルで行われる必要があります。
- 既にビューの 1 つ以上のレイヤーが存在しており、追加のビュー レイヤーを追加すると、パフォーマンスが低下する可能性があります。

### <a name="table-considerations"></a>テーブルに関する考慮事項

異なるテクノロジ間でテーブルを移行する場合、通常は、2 つの環境間で物理的に移動される生データ (およびそれを記述するメタデータ) のみが移行されます。 ソース システムのその他のデータベース要素 (インデックスなど) は移行されません。これは、これらの要素が必要ないか、新しいターゲット環境内で異なる方法で実装される可能性があるためです。

ただし、インデックスなどのパフォーマンスの最適化がソース環境で使用されている場所を理解することが重要です。これは、新しいターゲット環境でパフォーマンスの最適化が追加される可能性のある場所を示す有益な情報となるためです。 たとえば、ソース Teradata 環境内で NUSI が作成されている場合、移行された Azure Synapse Analytics 内で非クラスター化インデックスを作成する必要があることを示している可能性がありますが、同一条件下での直接的なインデックスの作成より、他のネイティブなパフォーマンス最適化手法 (テーブル レプリケーションなど) 方が適していることがあります。

### <a name="high-availability-for-the-database"></a>データベースの高可用性

Teradata では、`FALLBACK` オプションによりノード間でのデータ レプリケーションがサポートされており、特定のノードに物理的に存在するテーブル行が、システム内の別のノードにレプリケートされます。 この方法では、ノード障害が発生した場合にデータが失われないことが保証され、フェールオーバー シナリオの基礎が提供されます。

Azure SQL Database での高可用性アーキテクチャの目的は、メンテナンス操作や障害の影響を心配せずに、データベースの稼働および実行の時間が 99.99% 以上になるように保証することです。 Azure では、パッチ適用、バックアップ、Windows および SQL のアップグレードなどの重要なサービス タスクに加えて、基本となるハードウェア、ソフトウェア、またはネットワークのエラーなどの計画外のイベントが自動的に処理されます。

Azure Synapse Analytics のデータ ストレージは、スナップショットを使用して自動的にバックアップされます。 これらのスナップショットは、復元ポイントを作成するサービスの組み込み機能です。 この機能を有効にする必要はありません。 サービスは自動復元ポイントを使用して復旧の SLA を維持するので、現時点では、ユーザーはこれらの復元ポイントを削除できません。

Azure SQL Data Warehouse では、1 日を通してデータ ウェアハウスのスナップショットが取得され、7 日間利用できる復元ポイントが作成されます。 この保持期間は変更できません。 Azure SQL Data Warehouse では、8 時間の回復ポイントの目標 (RPO) がサポートされています。 プライマリ リージョンのデータ ウェアハウスを、過去 7 日間に作成されたいずれかのスナップショットから復元することができます。 より小さい単位でのバックアップが必要な場合は、他のユーザー定義オプションを使用できます。

### <a name="unsupported-teradata-table-types"></a>サポートされていない Teradata テーブル型

Teradata には、時系列とテンポラル データに対する特殊なテーブル型のサポートが含まれています。 これらのテーブル型に対する構文と一部の関数は、Azure Synapse Analytics では直接サポートされていませんが、適切なデータ型を使用してデータを標準テーブルに移行し、日付/時刻列でインデックス作成またはパーティション分割することができます。

Teradata では、クエリの書き換えによってテンポラル クエリ内にフィルターを追加し、該当する日付範囲を制限することにより、テンポラル クエリ機能が実装されます。 この機能がソース Teradata 環境内で現在使用されており、移行する場合は、関連するテンポラル クエリにこの追加のフィルター処理を追加する必要があります。

Azure 環境には、大規模な時系列データに対する複雑な分析のための、Time Series Insights と呼ばれる特定の機能も含まれています。 これは、IoT データ分析アプリケーションを対象としており、このユース ケースにいっそう適している場合があります。 詳細については、「[Azure Time Series Insights](https://azure.microsoft.com/services/time-series-insights/)」を参照してください。

### <a name="teradata-data-type-mapping"></a>Teradata データ型のマッピング

Teradata の一部のデータ型は、Azure Synapse Analytics では直接サポートされていません。 次の表では、これらのデータ型と、それらの推奨される処理方法を示します。 表で、Teradata の列の型はシステム カタログに格納される型です (例: `DBC.ColumnsV`)。

Teradata カタログ テーブルのメタデータを使用して、これらのデータ型のいずれかを移行する必要があるかどうかを判断し、移行プランでそれに対処できるようにします。 たとえば、次のような SQL クエリを使用して、注意が必要なサポートされていないデータ型の使用を検出できます。

前述のように、データ型のマッピングなど、移行を自動化するためのツールとサービスを提供するサードパーティ ベンダーが存在します。 また、Informatica や Talend などのサードパーティの ETL ツールが Teradata 環境で既に使用されている場合は、必要なデータ変換を実装できます。

## <a name="sql-dml-syntax-differences"></a>SQL DML 構文の相違点

Teradata SQL と Azure Synapse Analytics では、SQL データ操作言語 (DML) の構文にいくつかの相違点があり、移行時に考慮する必要があります。

- **QUALIFY:** Teradata では、`QUALIFY` 演算子がサポートされています。 次に例を示します。

  `SELECT col1 FROM tab1 WHERE col1='XYZ'`

  サードパーティのツールとサービスを使用すると、データ マッピング タスクを自動化できます。

  `QUALIFY ROW_NUMBER() OVER (PARTITION by col1 ORDER BY col1) = 1;`

  Azure Synapse では、次の構文を使用してこれを実現できます。

  `SELECT * FROM (SELECT col1, ROW_NUMBER() OVER (PARTITION by col1 ORDER BY col1) rn FROM tab1 WHERE c1='XYZ' ) WHERE rn = 1;`

- **日付の算術演算子:** Azure Synapse には、次のような演算子があります。

  - `DATEADD` および `DATEDIFF`。これらは、`DATE` または `DATETIME` フィールドで使用できます。 Teradata では、次のような日付の直接減算がサポートされています。

    `SELECT DATE1 - DATE2 FROM ...`

  - 次のような `LIKE ANY` 構文があります。

    `SELECT * FROM CUSTOMER WHERE POSTCODE LIKE ANY ('CV1%', 'CV2%', CV3%') ;`.

    Azure Synapse の構文で相当するものは次のとおりです。

    `SELECT * FROM CUSTOMER WHERE (POSTCODE LIKE 'CV1%') OR (POSTCODE LIKE 'CV2%') OR (POSTCODE LIKE 'CV3%') ;`

- システム設定によっては、Teradata の文字比較で、既定では大文字と小文字が区別されない場合があります。 Azure Synapse の場合、これらの比較では常に大文字と小文字が区別されます。

## <a name="functions-stored-procedures-triggers-and-sequences"></a>関数、ストアド プロシージャ、トリガー、シーケンス

Teradata などの成熟したレガシ データ ウェアハウス環境から移行するときは、単純なテーブルとビュー以外の要素を、新しいターゲット環境に移行することが必要になる場合がよくあります。 このようなものの例としては、関数、ストアド プロシージャ、トリガー、シーケンスがあります。

準備フェーズの一環として、プロジェクト計画で割り当てられているリソースの適切な配分を使用して、移行対象のこれらのオブジェクトのインベントリを作成し、それらのオブジェクトの処理方法を定義する必要があります。

Azure 環境内の機能により、Teradata 環境で関数またはストアド プロシージャとして実装されている機能が置き換えられる場合があります。 この場合、通常は、Teradata の関数をコーディングし直すより、Azure の組み込み機能を使用する方が効率的です。

これらの各要素の詳細については、以下を参照してください。

### <a name="functions"></a>関数

ほとんどのデータベース製品と同様に、Teradata ではシステム関数と SQL 実装内のユーザー定義関数もサポートされています。 Azure Synapse などの別のデータベース プラットフォームに移行する場合、通常は共通のシステム関数を使用でき、変更なしに移行することができます。 システム関数によっては構文が若干異なることがありますが、この場合は必要な変更を自動化できます。

同等のものがないシステム関数や、任意のユーザー定義関数の場合は、ターゲット環境で使用可能な言語を使用してコーディングし直すことが必要になる場合があります。 Azure Synapse では、ユーザー定義関数の実装に一般的な Transact-SQL 言語が使用されています。

### <a name="stored-procedures"></a>ストアド プロシージャ

最新のデータベース製品では、データベース内にプロシージャを格納できます。 Teradata では、この目的に SPL 言語が提供されています。 ストアド プロシージャには、通常、SQL ステートメントといくつかの手続き型のロジックが含まれており、データや状態を返すことができます。

SQL Azure Data Warehouse では T-SQL を使用するストアド プロシージャもサポートされているので、移行するストアド プロシージャがある場合は、それに応じてコーディングし直す必要があります。

### <a name="triggers"></a>トリガー

Azure Synapse 内ではトリガーの作成はサポートされていませんが、Azure Data Factory 内で実装できます。

### <a name="sequences"></a>シーケンス

Azure Synapse のシーケンスは、`IDENTITY` を使用するか、SQL コードを使用して系列の次のシーケンス番号を作成することにより、Teradata と同様の方法で処理されます。

## <a name="extracting-metadata-and-data-from-a-teradata-environment"></a>Teradata 環境からのメタデータとデータの抽出

### <a name="data-definition-language-ddl-generation"></a>データ定義言語 (DDL) の生成

Teradata の既存の `CREATE TABLE` および `CREATE VIEW` スクリプトを編集して、同等の定義を作成することができます (前述のように、必要に応じて、変更されたデータ型を使用します)。 通常、これには Teradata 固有の余分な句 (`FALLBACK` など) の削除が含まれます。

ただし、既存の Teradata 環境内のテーブルおよびビューの現在の定義を指定するすべての情報は、システム カタログ テーブル内で保持されます。 これは、最新かつ完全であることが保証されているため、この情報源として最適です。 ユーザーが管理するドキュメントは、現在のテーブル定義と同期されていない可能性があります。

この情報には `DBC.ColumnsV` などのカタログに対するビューからアクセスでき、Azure Synapse の同等のテーブルに対する同等の `CREATE TABLE` DDL ステートメントを生成するために使用できます。  

サードパーティの移行および ETL ツールでも、カタログ情報を使用して同じ結果が得られます。

### <a name="data-extraction-from-teradata"></a>Teradata からのデータの抽出

`BTEQ` や `FASTEXPORT` などの標準的な Teradata ユーティリティを使用して、既存の Teradata テーブルから生データを移行します。 一般に、移行の実行中は、できるだけ効率的にデータを抽出することが重要であり、Teradata の最近のバージョンでこのための推奨される方法は、複数の並列 `FASTEXPORT` ストリームを使用して最高のスループットを実現する Teradata Parallel Transporter を使用することです。

Teradata Parallel Transporter は、Azure Data Factory から直接呼び出すことができ、これはデータ移行プロセスを管理するための推奨される方法です (前に説明したように、これは、オンプレミスの Teradata インスタンスでも、Azure 環境内の VM にコピーされた場合でも当てはまります)。  
抽出されたデータに対して推奨されるデータ形式は、区切りテキスト ファイル (コンマ区切り値などとも呼ばれる) か、Optimized Row Columnar (ORC) または Parquet ファイルです。

Teradata 環境からデータと ETL を移行するプロセスの詳細については、関連ドキュメントのセクション 2.1. Teradata からのデータ移行 ETL と読み込みに関する記事を参照してください。

## <a name="performance-recommendations-for-teradata-migrations"></a>Teradata の移行に関するパフォーマンスの推奨事項

パフォーマンス チューニング アプローチの相違点

### <a name="data-distribution-options"></a>データ分散オプション

Azure では、個々のテーブルに対してデータ分散方法を指定できます。 その目的は、クエリの実行時に、処理ノード間で移動する必要があるデータの量を減らすことです。  

大きなテーブル同士の結合では、一方または両方 (理想的には両方) のテーブルの結合列にハッシュを分散すると、結合するデータ行が同じ処理ノードに既に併置されているので、結合処理をローカルに実行できることが保証されます。

小さいテーブルと大きいテーブルの結合 (通常は、スター スキーマ モデルでディメンション テーブルからファクト テーブルへ) のためのローカル結合を実現するもう 1 つの方法は、小さい方のディメンション テーブルをすべてのノードにレプリケートすることであり、それにより大きい方のテーブルの結合キーのどの値にも、対応するディメンション行がローカルに存在するようになります。 ディメンション テーブルが大きくない場合、テーブルをレプリケートする場合のオーバーヘッドは比較的低くなります。 この場合、前述のハッシュ分散アプローチが適しています。

### <a name="data-indexing"></a>データのインデックス作成

Azure Synapse には、インデックス作成オプションがいくつか用意されていますが、これらは Teradata での実装とは操作および使用方法が異なります。 さまざまなインデックス作成オプションの詳細については、[Azure Synapse プールでのテーブルの設計](https://docs.microsoft.com/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-overview)に関するページを参照してください。

一方、ソース Teradata 環境内の既存のインデックスでは、データが現在どのように使用されているかをわかりやすく示すことができ、Azure Synapse 環境内でインデックスを作成するための候補も示すことができます。

### <a name="data-partitioning"></a>データのパーティション分割

エンタープライズ データ ウェアハウスでは、ファクト テーブルに多数の行を含めることができます。パーティション分割を使用すると、これらのテーブルを別々の部分に分割して、処理されるデータの量を減らすことで、これらのテーブルのメンテナンスとクエリを最適化することができます。 テーブルのパーティション分割指定は、`CREATE TABLE` ステートメントで定義されます。

パーティション分割に使用できるフィールドは、各テーブルに 1 つだけです。多くのクエリは日付や日付範囲によってフィルター処理されるため、パーティション分割には日付フィールドが頻繁に使用されます。 必要に応じて、`CREATE TABLE AS SELECT` ステートメントを使用し、新しい分散を指定してテーブルを再作成することにより、初期読み込み後にテーブルのパーティション分割を変更することができます。 Azure Synapse でのパーティション分割の詳細については、「[Synapse SQL プールでのテーブルのパーティション分割](https://docs.microsoft.com/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-partition)」を参照してください。

### <a name="data-table-statistics"></a>データ テーブルの統計

データ テーブルの統計が最新であることを確認します。 これを行うには、ETL/ELT ジョブに対する `COLLECT STATISTICS` ステップで作成するか、テーブルの自動統計収集を有効にします。

### <a name="polybase-for-data-loading"></a>データ読み込み用の PolyBase

PolyBase は、並列読み込みストリームを使用できるため、ウェアハウスに大量のデータを読み込むための最も効率的な方法です。

### <a name="use-resource-classes-for-workload-management"></a>ワークロードの管理にリソース クラスを使用する

Azure Synapse Analytics では、リソース クラスを使用してワークロードが管理されます。 一般に、リソース クラスが大きいほど、クエリのパフォーマンスが向上します。一方、リソース クラスが小さいほど、より高いレベルの同時実行が可能になります。 使用率を動的管理ビューで監視して、適切なリソースが効率的に使用されていることを確認することができます。

## <a name="next-steps"></a>次のステップ

Teradata 移行の実装の詳細については、オンプレミスの移行プランについて Microsoft アカウント担当者にお問い合わせください。

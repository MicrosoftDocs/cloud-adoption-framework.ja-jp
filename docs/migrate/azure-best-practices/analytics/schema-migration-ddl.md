---
title: スキーマ移行のデータ定義言語 (DDL)
description: 高可用性とディザスター リカバリーの要件に、Azure Synapse の機能を使用して対処できます。
author: v-hanki
ms.author: brblanch
ms.date: 07/14/2020
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: migrate
ms.openlocfilehash: 50c4233325ffd1663331d0bf36d5fcb4b32cda7b
ms.sourcegitcommit: 9163a60a28ffce78ceb5dc8dc4fa1b83d7f56e6d
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/17/2020
ms.locfileid: "86452663"
---
<!-- cSpell:ignore DDLs Attunity "Attunity Replicate" "Attunity Visibility" Inmon Denodo Teradata Netezza Wherescape DMVs multinode equi Datometry -->

# <a name="schema-migration-data-definition-languages-ddls"></a>スキーマ移行のデータ定義言語 (DDL)

## <a name="design-considerations"></a>設計上の考慮事項

### <a name="preparation-for-migration"></a>移行の準備

既存のデータを Azure Synapse Analytics に移行するための準備では、実施する範囲を明確に定義することが重要です (最初の移行プロジェクトの場合は特に重要です)。 前もって時間を取り、移行する必要のあるデータベース オブジェクトと関連プロセスを理解することは、その後のプロジェクトでの労力とリスクを軽減するのに役立ちます。

移行するデータベース オブジェクトのインベントリを作成します。 ソース プラットフォームに応じて、このインベントリには次のオブジェクトの一部またはすべてが含まれます。

- テーブル
- Views
- Indexes
- 関数
- ストアド プロシージャ
- データ分散とパーティション分割

これらのオブジェクトの基本情報 (行数、物理サイズ、データ圧縮率、オブジェクトの依存関係などのメトリックを含む) は、ソース システムのシステム カタログ テーブルに対するクエリを通じて利用できる必要があります。 システム メタデータは、この情報の最適なソースです。 外部のドキュメントは、情報が古くなっており、初期の実装以降にデータ構造に適用された変更と同期していない可能性があります。

実際のオブジェクトの使用状況をクエリ ログから分析したり、Microsoft パートナーのツールを使用したりて Attunity Visibility などに活用することもできます。 一部のテーブルは、実稼働クエリでは使用されなくなっていて、移行する必要がない場合もあります。

データのサイズ設定とワークロードの情報 (必要な同時実行のレベルなど) は、Azure Synapse Analytics の適切な構成を定義するのに使用されるため、重要です。 データとワークロードの将来的な成長を予測しておくこともお勧めします。これは、推奨されるターゲット構成にも影響する可能性があります。

新しいターゲット プラットフォームに必要なストレージを見積もるためにデータ ボリュームを使用するときには、ソース データベースのデータ圧縮率 (圧縮している場合) を理解することが重要です。 ソース システムで使用されているストレージの量をそのまま使用すると、サイズ設定の根拠を誤る可能性があります。 監視情報やメタデータ情報を基に、現在のシステムの圧縮されていない生データのサイズに加えて、インデックス作成、データ レプリケーション、ログ記録、その他のプロセスのオーバーヘッドを判別できるはずです。

移行する必要のあるテーブルの圧縮されていない生データ サイズは、新しいターゲット Azure Synapse Analytics 環境で必要とされるストレージを見積もる際に最初に考慮することをお勧めします。

圧縮要素や、新しいターゲット プラットフォームでのインデックス作成オーバーヘッドもありますが、通常これらはソース システムによって異なります。 Azure Synapse Analytics のストレージ価格には、7 日間のスナップショット バックアップも含まれています。 この点も、既存の環境と比較して、必要とされるストレージの全体的なコストに影響を与える可能性があります。

データ モデルのパフォーマンス チューニング プロセスは、移行プロセスの終盤まで手を付けずに残しておいて、データ ウェアハウス内に実際のデータ ボリュームが存在するようになってから実行することもできます。 とはいえ、いくつかのパフォーマンス チューニング オプションを、プロセスの早い段階で実装しておくことをお勧めします。 たとえば、Azure Synapse Analytics では、通常、小さいディメンション テーブルをレプリケート テーブルとして定義し、大きいファクト テーブルをクラスター化列ストア インデックスとして定義するのが理にかなっています。 同様に、ソース環境で定義されたインデックスは、新しい環境でインデックスを作成することからメリットが得られる可能性のある列を判断するのに役立ちます。 テーブルを読み込むより前の、テーブルを最初に定義する時点でこの情報を使用すると、プロセスの後半で時間を節約できます。

Azure Synapse Analytics で使用するデータの圧縮率やインデックス オーバーヘッドは、移行プロジェクトの進行に応じて測定することをお勧めします。 この測定を基に、将来的なキャパシティ プランニングを行うことができます。

移行前に既存のデータ ウェアハウスを簡素化して、複雑さを軽減することにより、移行を容易にすることもできます。 これには、次のことが含まれます。

- 使用していないテーブルを移行前に削除またはアーカイブして、使用していないデータを移行しないようにします。 データを Azure Blob Storage にアーカイブして外部テーブルとして定義すると、そのデータを使用できる状態に維持しながら、コストを削減できます。
- データ仮想化ソフトウェアを使用して物理データ マートを仮想データ マートに変換し、移行する必要のあるものを削減します。 この変換により、機敏性の向上と総保有コストの削減も達成できます。これは、移行時の最新化と見なすことができます。

Inmon スタイルのデータ モデルからデータ コンテナー アプローチに移行するなど、基になるデータ モデルを変更することによってウェアハウスを最新化することは、移行を行う目的の 1 つです。 これは、準備フェーズの一部として決定する必要があり、その切り替え戦略を移行計画に組み込む必要があります。 このシナリオでは、データ モデルを最初は現状のままで新しいプラットフォームに移行し、その後に Azure Synapse Analytics で新しいモデルに切り替える方法をお勧めします。そのようにすれば、ソース システムに影響を与えずに、そのプラットフォームのスケーラビリティとパフォーマンス特性を活かして変換を実行できます。

### <a name="data-model-migration"></a>データ モデルの移行

ソース システムのプラットフォームとオリジンによっては、一部またはすべての部分のデータ モデルが既にスター スキーマまたはスノーフレーク スキーマ形式になっている場合があります。 その場合、それはそのまま直接 Azure Synapse Analytics に移行できます。 このシナリオは、実現できる最も簡単で最もリスクの低い移行です。 現状のままで行える移行は、上述のデータ コンテナーなどの、基になる新しいデータ モデルへの切り替えを含む、より複雑な移行の最初の段階でもあります。

どのようなセットのリレーショナル テーブルとビューであっても Azure Synapse Analytics に移行できますが、大規模なデータ セットに対する分析クエリ ワークロードの場合、通常はスター データ モデルかスノーフレーク データ モデルを使用すると、全体として最適なパフォーマンスを実現できます。 ソース データ モデルがまだこの形式になっていない場合は、移行プロセスを使用してモデルを再エンジニアリングする価値があることもあります。

移行プロジェクトの一部としてデータ モデルに変更を加える場合のベスト プラクティスは、そのような変更を新しいターゲット環境で実行することです。つまり、既存のモデルをまず移行し、その後に、Azure Synapse Analytics のパワーと柔軟性を活かして、データを新しいモデルに変換します。 この方法で実行すると、既存のシステムへの影響を最小限に抑えつつ、Azure Synapse Analytics のパフォーマンスとスケーラビリティを利用して、変更を迅速かつコスト効率よく行うことができます。

移行する既存のシステムが、いくつかのレイヤー (データの取り込みまたはステージング レイヤー、データ ウェアハウス レイヤー、レポート レイヤーやデータ マート レイヤーなど) として実装されており、そのそれぞれが多くのリレーショナル テーブルとビューで構成されている場合があります。 これらをすべて現状のままで Azure Synapse Analytics に移行することもできますが、すべてを直接移行するよりも、Azure エコシステムの機能の一部を使用する方がコスト効率とパフォーマンスが向上する可能性があります。 次に例を示します。

- **データの取り込みとステージング:** Azure Blob Storage と PolyBase を併用した並列データの高速読み込みを、リレーショナル テーブルの代わりに ETL/ELT プロセスの一部で使用できます。
- **レポート レイヤーとデータ マート:** Azure Synapse Analytics のパフォーマンス特性によって、レポート目的やデータ マート用に集計されたテーブルを物理的にインスタンス化する必要がなくなる場合があります。 これらをビューとしてコア データ ウェアハウスに実装したり、サードパーティのデータ仮想化レイヤー経由で実装したりできます。 基本レベルでは、履歴データのデータ移行プロセスと、場合によっては増分更新を、以下に示されているように実現できます。

![最新のデータ ウェアハウス](../../../_images/analytics/schema-migration-ddl.png)

これらの方法や同様の方法を使用できる場合、移行する必要のあるテーブル数が減り、一部のプロセスは簡略化できたり不要になったりするため、移行のワークロードを削減できます。 これらの方法を活用できるかどうかはユース ケースごとに異なりますが、一般的な原則として、移行ワークロードを削減し、コスト効率の高いターゲット環境を構築するために、可能な限り Azure エコシステムの機能を使用することを検討することができます。 これは、バックアップと復元、ワークフローの管理や監視などの他の機能にも当てはまります。

データ ウェアハウスの移行や、場合によってはプロセスの一部の自動化に役立つ、Microsoft パートナーから提供されている製品やサービスもあります。 既存のシステムにサードパーティの ETL 製品が組み込まれている場合は、Azure Synapse Analytics がターゲット環境として既にサポートされていて、既存の ETL ワークフローを新しいターゲット Azure SQL Data Warehouse にリダイレクトできる可能性があります。

### <a name="data-marts-physical-or-virtual"></a>データ マート:物理データ マートと仮想データ マート

従来のデータ ウェアハウス環境では、組織内の特定の部門またはビジネス機能に対して、パフォーマンスの優れたアド ホック セルフサービス クエリとレポート機能を提供するために構成された多数のデータ マートを作成するのが一般的です。 そのため、データマートは通常、ユーザーが Tableau、MicroStrategy、Microsoft Power BI などのユーザーフレンドリなクエリ ツールを使用して速い応答時間で簡単にデータをクエリできる形式の、集計されたバージョンのデータを格納するデータ ウェアハウスのサブセットで構成されます。 この形式は通常、次元データ モデルです。データ マートの使用方法の 1 つは、基になるウェアハウスのデータ モデルが異なる (データ コンテナーなど) 場合でも、使用可能な形式でデータを公開することです。 この方法は、3 層モデルとも呼ばれます。

組織内の個々の部署に対してデータ マートを分離して使用すると、ユーザーに関係する特定のデータ マートへのユーザー アクセスのみを許可し、機密データを排除、難読化、または匿名化することにより、堅牢なデータ セキュリティ体制を実装できます。

これらのデータ マートが物理テーブルとして実装されている場合は、それらを格納するための追加のストレージ リソースと、それらを定期的にビルドおよび更新するための追加の処理が必要になります。 このことは、マート内のデータは最後の更新操作の時点での最新の状態を保っているにすぎないため、変動の激しいデータ ダッシュボードには適していない可能性があることも意味しています。

Azure Synapse Analytics などの比較的安価でスケーラブルな超並列処理 (mpp) アーキテクチャの出現とそれらに固有のパフォーマンス特性により、マートを物理テーブルのセットとしてインスタンス化しなくても、データマート機能を実現できるようになりました。 これは、データ マートの効率的な仮想化を、SQL ビューを介してメイン データ ウェアハウスに対して行うか、Azure Synapse Analytics のビューや Denodo などのサードパーティの仮想化製品のビューなどの機能を使用して仮想化レイヤーを介して行うことにより実現されます。 この方法を使用すると、追加のストレージと集計処理の必要性が軽減されるか不要になるため、移行する必要のあるデータベース オブジェクトの総数を削減できます。

この方法には、潜在的な利点がもう 1 つあります。 仮想化レイヤー内に集計と結合のロジックを実装し、仮想化されたビューを介して外部レポート ツールを表示することにより、これらのビューを作成するのに必要な処理がデータ ウェアハウスにプッシュ ダウンされます。データ ウェアハウスは、通常、大量のデータに対して結合や集計などの操作を実行するのに最適な場所です。

物理データ マートと仮想データ マートのどちらを実装するかを選択するための主な要素を以下に示します。

- 仮想データ マートの方が、物理テーブルとその関連 ETL プロセスよりも変更しやすいため、機敏性が向上する。
- 仮想化された実装でデータ ストアとデータのコピーが少なくなるため、総保有コストを削減できる。
- 移行のための ETL ジョブを排除でき、仮想化環境の dw アーキテクチャが簡素化される。
- パフォーマンス: 仮想化製品にパフォーマンスの差を軽減するためのインテリジェントなキャッシュ手法が実装されるようになっているとはいえ、これまでのところ物理データ マートの方がパフォーマンスは優れている。

データの仮想化は、移行プロジェクトの実行中に、エンド ユーザーに一貫性のあるデータ ビューを提供する目的でも使用できます。

### <a name="data-mapping"></a>データ マッピング

**Azure Synapse Analytics のキー制約および整合性制約:**

主キー制約や外部キー制約は、Azure Synapse Analytics 内では現在適用されていませんが、`PRIMARY KEY` の定義を `NOT ENFORCED` 句を使用して `CREATE TABLE` ステートメント内に含めることができます。 これは、サードパーティのレポート製品で、データ モデル内のキーを解釈して最も効率的なクエリを生成するために、テーブルのメタデータを使用できることを意味しています。

**Azure Synapse Analytics のデータ型サポート:**

一部のレガシ データベース システムには、Azure Synapse Analytics では現在直接サポートされていないデータ型のサポートが含まれています。 ただし、これらのデータ型は通常、サポートされているデータ型を使用してデータを現状のまま格納するか、サポートされているデータ型にデータを変換することによって処理できます。

サポートされているデータ型の一覧をアルファベット順で以下に示します。

<!-- TODO: Review format of this list. Are the arguments necessary for this list? -->

<!-- docsTest:disable -->

- `bigint`
- `binary [ (n) ]`
- `bit`
- `char [ (n) ]`
- `date`
- `datetime`
- `datetime2 [ (n) ]`
- `datetimeoffset [ (n) ]`
- `decimal [ (precision [, scale ]) ]`
- `float [ (n) ]`
- `int`
- `money`
- `nchar [ (n) ]`
- `numeric [ (precision [ , scale ]) ]`
- `nvarchar [ (n | MAX) ]`
- `real [ (n) ]`
- `smalldatetime`
- `smallint`
- `smallmoney`
- `time [ (n) ]`
- `tinyint`
- `uniqueidentifier`
- `varbinary [ (n | MAX) ]`
- `varchar [ (n | MAX) ]`

<!-- docsTest:enable -->

次の表に、現在サポートされていないいくつかの一般的なデータ型と、それらを Azure Synapse Analytics に格納するために推奨される方法を示します。 (Teradata や Netezza などの特定の環境の詳細については、関連するドキュメントを参照してください。)

| **サポートされていないデータ型** | **回避策**                                                      |
|-----------------------|-----------------------------------------------------------------|
| `geometry`              | `varbinary`                                                       |
| `geography`             | `varbinary`                                                       |
| `hierarchyid`           | `nvarchar(4000)`                                                  |
| `image`                 | `varbinary`                                                       |
| `text`                  | `varchar`                                                         |
| `ntext`                 | `nvarchar`                                                        |
| `sql_variant`           | 列を厳密に型指定された複数の列に分割                |
| `table`                 | 一時テーブルに変換                                     |
| `timestamp`             | `datetime2` と `CURRENT_TIMESTAMP` 関数を使用するようにコードを再作成 |
| `xml`                   | `varchar`                                                         |
| ユーザー定義型     | 可能な場合は、ネイティブ データ型に戻す              |

**潜在的なデータの問題:**

ソース環境によっては、データの移行時に問題の原因となりうる問題がいくつかあります。

- 異なるデータベース製品では、`NULL` データの処理方法が微妙に異なります。これには、照合順序のシーケンスや空の文字列の処理などが含まれます。
- `DATE`、`TIME`、`INTERVAL`、`TIME ZONE` データと関連する関数は、製品によって大きく異なる場合があります。

ターゲット環境で確実に目的の結果が得られるようにするため、これらを徹底的にテストしてください。 移行を実行すると、既存のソース システムの一部になっているバグや正しくない結果が明らかになる場合もあります。 移行プロセスは、こうした異常を修正する絶好の機会です。 Azure Synapse Analytics で列を定義するためのベスト プラクティスとしては、従来のシステムで、非効率的なデータ型で指定された列を検索するのが一般的です。たとえば、実際のデータ値は `CHAR(5)` フィールドに収まるのに `VARCHAR(20)` として定義されるフィールドや、すべての値が `SMALLINT` フィールド内に収まるのに `INTEGER` フィールドを使用している場合があります。 このような場合、特に大規模なファクト テーブルでは、ストレージとクエリの両方のパフォーマンスが低下する可能性があります。

移行は、既存のデータ定義を確認し、データ定義を合理化する良い機会です。 これは、SQL クエリを使用してデータ フィールド内の最大の数値や最大文字数を検索し、データ型と比較することによって自動化できます。 一部のサードパーティ データ探索ツールや移行ツールにも、この機能が組み込まれています。

一般に、テーブルに対して定義されている行の長さの合計を最小限に抑えることが推奨されています (上述のように、各列に対して最小のデータ型を使用することなどにより)。そうすることにより、最適なクエリ パフォーマンスが得られます。 PolyBase ユーティリティは、Azure Synapse Analytics の外部テーブルからのデータ読み込みに推奨される方法で、定義される行の長さとして 1 MB の最大値をサポートしています。 長さが 1 MB を超える行については、PolyBase でそのテーブルを読み込むことはできません。代わりに、bcp を使用する必要があります。

結合を最も効率的に実行するには、結合の両側で使用される列を同じデータ型として定義します。 ディメンション テーブルのキーが `SMALLINT` として定義されている場合は、そのディメンションを使用するファクト テーブルの対応する参照列も `SMALLINT` として定義する必要があります。

文字フィールドは既定のサイズを大きく定義しないでください。 フィールド内のデータの最大サイズが 50 文字の場合は、`VARCHAR(50)` を使用します。 同様に、`VARCHAR` で十分な場合は `NVARCHAR` を使用しないでください。 `NVARCHAR` では、さまざまな言語の文字セットを使用できるように Unicode データが格納されますが、`VARCHAR` には ASCII データが格納されるためスペースが少なくて済みます。

## <a name="design-recommendations-summary"></a>設計上の推奨事項の概要

不要なオブジェクトやプロセスは移行しないようにします。 移行するオブジェクトやプロセスの実際の数を減らすのが適している場合は、ターゲットの Azure 環境の組み込み機能と関数を使用します。 移行する物理データ マートを削減するかなくして、処理をデータ ウェアハウスにプッシュ ダウンするため、仮想化レイヤーの使用を検討します。

可能な限り、処理を自動化します。 ソース システムのシステム カタログのメタデータを使用して、ターゲット環境の DDL を生成します。 可能であれば、ドキュメントの生成も自動化します。 Wherescape などの Microsoft パートナーは、これを支援するための特別なツールやサービスを提供できます。

必要なデータ モデルの変更やデータ マッピングの最適化は、ターゲット プラットフォーム上で実行します。 このような変更は、Azure Synapse Analytics で行う方が効率的に実行できます。 この方法により、キャパシティの限界ぎりぎりで既に実行している可能性のあるソース システムに対する影響を軽減できます。

## <a name="performance-options"></a>パフォーマンス オプション

このセクションでは、特定のデータ モデルのパフォーマンスを向上させるために Azure Synapse Analytics で使用できる機能について説明します。

### <a name="general-approach"></a>一般的なアプローチ

移行するデータベースには、そのプラットフォームで使用可能な機能 (インデックス、データのパーティション分割、そして場合によってはデータ分散など) を使用して、パフォーマンスのチューニングが既に適用されています。 移行の準備の一環として、これらをドキュメント化する必要があります。これは、Azure Synapse Analytics のターゲット環境で適用できる最適化の適切な判断材料になります。

たとえば、テーブルに一意でないインデックスが存在する場合、そのインデックスで使用されているフィールドが、フィルター処理、グループ化、または結合に頻繁に使用されていることを示している可能性があります。 新しい環境でも同様に使用されるので、インデックスを付けるフィールドを選択するときにこのことを念頭に置く必要があります。 Teradata や Netezza などの特定のソース プラットフォームの移行の推奨事項については、個別のドキュメントで詳しく説明されています。

ターゲットの Azure Synapse Analytics 環境のパフォーマンスとスケーラビリティを活用して、データ分散などのさまざまなパフォーマンス オプションを試し、代替アプローチの中から最適な選択肢を決定します (例: 大きなディメンション テーブルにレプリケートを使用するかハッシュ分散を使用するか)。 そのために外部ソースからデータを再読み込みする必要はありません。 Azure Synapse Analytics では、`CREATE TABLE AS SELECT` ステートメントを使用し、さまざまなパーティション分割オプションや分散オプションを指定してテーブルのコピーを作成することにより、比較的短時間で簡単に代替アプローチをテストできます。

Azure 環境に用意されている監視ツールを使用して、クエリがどのように実行され、どこにボトルネックが発生している可能性があるかを把握できます。 監視ダッシュボードや、自動化されたリソース管理とアラート処理を提供するサードパーティの Microsoft パートナー製ツールも利用できます。

Azure Synapse Analytics の各 SQL 操作は、そのクエリで使用されるリソース (メモリや CPU など) と共にシステム テーブルに記録されます。また、この情報に簡単にアクセスできるようにするために、一連の動的管理ビュー (DMV) が提供されています。

以下のセクションでは、クエリ パフォーマンスをチューニングするための Azure データ ウェアハウス内の主要なオプションについて説明します。 既存の環境には、ターゲット環境での最適化に役立つ可能性がある情報が含まれます。

### <a name="temporary-tables"></a>一時テーブル

Azure Synapse Analytics では一時テーブルがサポートされています。一時テーブルは、それが作成されたセッションにのみ表示され、ユーザー セッションの間は存在し、そのセッションの終了時に自動的に削除されます。

一時テーブルを作成するには、テーブル名の先頭にハッシュ文字 (`#`) を付けます。 一時テーブルには、通常のインデックス作成オプションと分散オプションをすべて使用できます (下記参照)。

一時テーブルには、以下に示すいくつかの制限があります。

- テーブル名の変更は許可されていません。
- 一時テーブルにはビューやパーティションは使用できません。
- 一時テーブルに対するアクセス許可は変更できません。

一時テーブルは、通常、ETL/ELT 処理で使用されます。この処理では、一時的な中間結果が変換プロセスの一部として使用されます。

### <a name="table-distribution-options"></a>テーブル分散オプション

Azure Synapse Analytics は、複数の処理ノードにまたがって並列に処理を実行することによってパフォーマンスとスケーラビリティを実現する、超並列処理 (mpp) データベース システムです。

複数ノード環境で SQL クエリを実行する場合の理想的な処理シナリオは、すべてのノードが同じ量のデータを処理するようにワークロードのバランスを取ると同時に、クエリを満たすためにノード間で移動する必要があるデータ量を最小限に抑える (または完全になくす) ことです。

一般的な分析クエリでは、複数の集計だけでなく、複数のテーブル間 (ファクト テーブルとディメンション テーブルの間など) に複数の結合もあることが多いため、理想的なシナリオを実現することが困難な場合があります。

クエリの処理に影響を与える方法の 1 つは、Azure Synapse Analytics 内の分散オプションを使用して、各テーブルの個々のデータ行が格納される場所を指定することです。 たとえば、2 つの大きなテーブルが、`CUSTOMER_ID` などの特定のデータ列で頻繁に結合される場合、その結合が実行されるたびに `CUSTOMER_ID` 列を使用して 2 つのテーブルを分散することにより、結合の各側のデータが同じ処理ノードに既に併置されているため、ノード間でデータを移動する必要をなくすることができます。 テーブルの分散指定は、`CREATE TABLE` ステートメントで定義されます。

使用可能な分散オプションと、それらをいつ使用するかに関する推奨事項を以下に示します。 必要に応じて、`CREATE TABLE AS SELECT` ステートメントを使用し、新しい分散を指定してテーブルを再作成することにより、初期読み込み後にテーブルの分散を変更することができます。

#### <a name="round-robin"></a>ラウンドロビン

このテーブル分散は既定のオプションで、システム内のノード間にデータを均等に分散します。 この方法は、データの高速読み込みや、比較的ボリュームが小さく、ハッシュの明確な候補を持たないデータの場合に適しています。このため、ETL プロセスや ELT プロセスの一部としてステージング テーブルに頻繁に使用されます。

#### <a name="hashed"></a>ハッシュ

ユーザー定義のキー (上の例の `CUSTOMER_ID` など) に適用されたハッシュ アルゴリズムに基づき、システムによって行がハッシュ バケットに割り当てられ、それが特定のノードに割り当てられます。 そのため、同じ値でハッシュ分散されたすべてのデータ行は、最終的に同じ処理ノード上に存在するようになります。

このメソッドは、特定のキーで頻繁に結合または集計される大きなテーブルに便利です。 結合する他の大きなテーブルは、可能であれば同じキーでハッシュする必要があります。 ハッシュ キーの候補が複数存在する場合は、最も頻繁に結合されるものを選択します。 ハッシュ列に null 値を含めることはできません。また、多くのクエリが日付を基にフィルター処理するため、ハッシュ列は通常は日付ではありません。 ハッシュするキーが `CHAR` や `VARCHAR` ではなく整数値である場合は、通常、ハッシュの方が効率的です。 かなりの割合のデータ行を表す少数のキー値など、値の範囲が非常に偏っているキーは選択しないようにします。

#### <a name="replicated"></a>レプリケート

テーブルの分散オプションとしてレプリケートを選択すると、クエリ処理の目的で、各コンピューティング ノードにそのテーブルの完全なコピーがレプリケートされます。

この方法は、比較的静的で、等結合によってより大きなテーブルに頻繁に結合される比較的小さなテーブル (通常は 2 GB 未満に圧縮されたもの) に役立ちます。 これらのテーブルは、多くの場合、スター スキーマ内のディメンション テーブルです。

### <a name="indexing"></a>インデックス作成

Azure Synapse Analytics には、レコードを取得するのに必要なリソースと時間を削減できるように、大きなテーブルのデータにインデックスを付けるためのオプションがいくつか用意されています。

- クラスター化列ストア インデックス
- クラスター化インデックス
- 非クラスター化インデックス

インデックス オプションを使用してもメリットが得られないテーブル向けに、`HEAP` と呼ばれる非インデックス オプションもあります。 インデックスを使用すると、クエリ時間は短縮できますが、読み込み時間は長くなり、ストレージ領域の使用量も多くなります。 多くの場合、インデックスを使用すると、データ行のごく一部にのみ影響する大きなテーブルに対する `SELECT`、`UPDATE`、`DELETE`、`MERGE` の操作速度は向上します。また、インデックスは、完全なテーブル スキャンを回避するのにも役立ちます。

`UNIQUE` 制約や `PRIMARY KEY` 制約が列に定義されると、インデックスが自動的に作成されます。

#### <a name="clustered-columnstore-index"></a>クラスター化列ストア インデックス

これは、Azure Synapse Analytics 内の既定のインデックス作成オプションで、大きなテーブルに対する最適な圧縮とクエリ パフォーマンスを実現できます。 小さいテーブル (6,000 万行未満) では、これらのインデックスは効率的ではないため、ヒープ オプションを使用する必要があります。 同様に、テーブル内のデータが一時的なものである場合 (ETL/ELT プロセスの一部である場合など) は、ヒープか一時テーブルの方が効率的な可能性があります。

#### <a name="clustered-index"></a>クラスター化インデックス

強力なフィルター条件に基づいて、大きなテーブルから 1 行または少数の行を定期的に取得する必要がある場合、クラスター化列ストア インデックスよりもクラスター化インデックスを使用する方が効率的な可能性があります。 クラスター化インデックスは、各テーブルに 1 つだけ許可されます。 レプリケーション

#### <a name="non-clustered-index"></a>非クラスター化インデックス

非クラスター化インデックスは、フィルター条件に基づいて 1 行または少数の行の取得を高速化できるという点で、クラスター化インデックスに似ています。 内部的に、非クラスター化インデックスはデータとは別に格納され、1 つのテーブルに対して複数の非クラスター化インデックスを定義できます。 ただし、インデックスを追加するたびにより多くのストレージが必要になり、データの挿入や読み込みのスループットは低下します。

#### <a name="heap"></a>ヒープ

ヒープ テーブルでは、データの読み込み時にインデックスの作成と保守に関連するオーバーヘッドは発生しません。そのため、一時的なデータをすばやく読み込む場合 (ETL プロセスの一部としてなど) に便利です。 この場合、その後すぐにデータの読み取りが実行されるため、キャッシュのメリットを活かせる可能性があります。 ヒープ テーブルは、6,000 万行未満のテーブルを格納する場合にも役立ちます。クラスター化列ストア インデックスは、このサイズ未満では非効率になるためです。

### <a name="data-partitioning"></a>データのパーティション分割

エンタープライズ データ ウェアハウスでは、ファクト テーブルに数 10 億行も含まれる場合があります。パーティション分割でこれらのテーブルを別々の部分に分割し、クエリ実行時に処理されるデータ量を減らすことにより、これらのテーブルのメンテナンスとクエリを最適化できます。 テーブルのパーティション分割指定は、`CREATE TABLE` ステートメントで定義されます。

パーティション分割に使用できるフィールドは、各テーブルに 1 つだけです。多くのクエリは日付や日付範囲によってフィルター処理されるため、パーティション分割には日付フィールドが頻繁に使用されます。 必要に応じて、`CREATE TABLE AS SELECT` ステートメントを使用し、新しい分散を指定してテーブルを再作成することにより、初期読み込み後にテーブルのパーティション分割を変更することができます。

#### <a name="partitioning-for-query-optimization"></a>クエリを最適化するためのパーティション分割

大きいファクト テーブルに対するクエリが特定のデータ列によって頻繁にフィルター処理される場合、その列をパーティション分割することにより、クエリを実行するために処理する必要のあるデータ量を大幅に削減できます。 一般的な例としては、日付フィールドを使用して、それぞれが 1 日のデータを含む小さいグループにテーブルを分割することが挙げられます。 日付でフィルター処理する `WHERE` 句がクエリに含まれている場合、その日付フィルターに一致するパーティションのみがアクセスされる必要があります。

#### <a name="partitioning-for-table-maintenance-optimization"></a>テーブルの維持を最適化するためのパーティション分割

データ ウェアハウス環境では、販売取引を 5 年間保持するなど、詳細なファクト データのローリング ウィンドウを維持するのが一般的です。 販売日を基にパーティション分割すると、ローリング ウィンドウを過ぎた古いデータの削除を非常に効率的に行うことができます。 最も古いパーティションを削除する方が、個々の行すべての中から削除するよりも速く、リソースの使用量を抑えることもできます。

### <a name="statistics"></a>統計

クエリは、Azure Synapse Analytics に送信されると、まずクエリ オプティマイザーによって処理されます。クエリ オプティマイザーによって、そのクエリを最も効率的に実行するためにどの内部メソッドを使用するかが決定されます。 オプティマイザーは、コストベースのアルゴリズムに基づいて、使用できるさまざまなクエリ実行プランを比較します。コスト見積もりの精度は、使用可能な統計に依存しています。 そのため、常に統計を最新に保つことをお勧めします。

Azure Synapse Analytics では、`AUTO_CREATE_STATISTICS` オプションがオンになっていると、統計の自動更新がトリガーされます。 統計は、`CREATE STATISTICS` コマンドを使用して手動で作成または更新することもできます。

コンテンツが大幅に変更されている場合 (日次更新など) には、統計を更新してください。 この更新は、ETL プロセスに組み込むことができます。

データベース内のすべてのテーブルは、少なくとも 1 つの列に関して統計が収集される必要があります (行数やテーブル サイズなどの基本的な情報をオプティマイザーで使用できるようにするため)。 統計が収集される必要のある他の列は、`JOIN`、`DISTINCT`、`ORDER BY`、`GROUP BY` の処理で指定されている列です。

### <a name="workload-management"></a>ワークロードの管理

Azure Synapse Analytics には、混合ワークロードのリソース使用率を管理するための包括的な機能が組み込まれています。 さまざまなワークロードの種類 (クエリとデータ読み込みなど) に対してリソース クラスを作成すると、同時実行されるクエリの数と、各クエリに割り当てられているコンピューティング リソースに制限を設定することにより、ワークロードを管理しやすくなります。 メモリとコンカレンシーの間にはトレードオフがあります。

- リソース クラスが少数の場合、クエリごとの最大メモリは減少しますが、コンカレンシーは増えます。
- より大規模なリソース クラスでは、クエリあたりの最大メモリは増えますが、コンカレンシーは減ります。

### <a name="performance-recommendations"></a>パフォーマンスに関する推奨事項

任意のパフォーマンス向上方法 (インデックス、データ分散など) を、新しいターゲット環境で同様の測定をする候補の指標として使用します。ただし、それらが必要であることを確認するため、Azure Synapse Analytics でベンチマークを実行します。 統計が最新であることを確認するため、または統計の自動作成を有効にするために、ETL/ELT プロセスに `COLLECT STATISTICS` ステップを構築します。

Azure Synapse Analytics で使用できるチューニング オプションと、並列データの高速読み込みを実現する PolyBase などの、関連するユーティリティのパフォーマンス特性を理解します。 これらのオプションを使用すると、効率的なエンドツーエンドの実装を構築できます。

Azure 環境の柔軟性、スケーラビリティ、パフォーマンスを使用して、データ モデルの変更やパフォーマンス チューニング オプションをインプレースで実装し、既存のソース システムに与える影響を軽減します。

システム全体のリソース使用率に関する情報と個々のクエリの詳細な実行情報の両方を提供する、Azure Synapse Analytics で使用できる動的管理ビューについて理解します。

Azure のリソース クラスについて理解し、それらを適切に割り当てて、混合ワークロードやコンカレンシーを効率的に管理できるようにします。

Azure Synapse Analytics 環境の一部として仮想化層を使用して、ウェアハウス実装の変更をビジネス ユーザーやレポート ツールからシールドすることを検討します。

サードパーティ プロバイダーによって提供されている、Attunity Replicate for Microsoft Migrations、Wherescape、Datometry などの移行ツールやサービスについて調査します。 これらのツールを使用すると、移行プロセスの一部を自動化して、移行プロジェクトに関係する経過時間やリスクを軽減できます。

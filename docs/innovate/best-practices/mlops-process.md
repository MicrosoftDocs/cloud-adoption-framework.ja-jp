---
title: 機械学習の運用プロセス
description: 機械学習の運用プロセスについて説明します。
author: mufajjul
ms.author: brblanch
ms.date: 01/20/2021
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: innovate
ms.custom: think-tank
ms.openlocfilehash: 19d4961034aca6505c93d3ccd408267c71dffba9
ms.sourcegitcommit: 9cd2b48fbfee229edc778f8c5deaf2dc39dfe2d6
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 02/01/2021
ms.locfileid: "99230672"
---
# <a name="the-machine-learning-operations-process"></a>機械学習の運用プロセス

## <a name="the-model-development-process"></a>モデルの開発プロセス

開発プロセスでは、次のような成果が得られます。

- トレーニングが自動化され、モデルが検証されます。これには、テスト機能とパフォーマンス (精度メトリックの使用など) が含まれます。

- 推論 (監視を含む) に使用されるインフラストラクチャへの展開が自動化されます。

- メカニズムにより、エンドツーエンドのデータ監査証跡が作成されます。 モデルの自動再トレーニングは、時間の経過とともにデータ ドリフトが発生した際に行われます。これは、機械学習が組み込まれた大規模なシステムに関係します。

次の図は、機械学習システムの展開ライフサイクルを示しています。

![機械学習ライフサイクルの図。](./media/ml-lifecycle.png)

開発が完了すると、機械学習モデルのトレーニング、検証、展開、および監視が行われます。 組織の観点から、また経営および技術的なレベルから、誰がこのプロセスを担当し、実装するのかを定義することが重要です。 大企業では、データ サイエンティストがモデルのトレーニングと検証の手順を担当し、機械学習エンジニアが残りの手順を担当する傾向があります。 より小規模な企業では、データ サイエンティストがすべての手順を担当することもあります。

### <a name="train-the-model"></a>モデルをトレーニングする

このステップでは、トレーニング データセットを使用して機械学習モデルをトレーニングします。 トレーニング コードはバージョン管理され、再利用可能です。この機能により、ボタンのクリックやイベント トリガー (データの新しいバージョンが使用可能になった場合など) が最適化され、モデルのトレーニング方法が自動化されます。

### <a name="validate-the-model"></a>モデルを検証する

このステップでは、精度メトリックなどの確立されたメトリックを使用して、新しくトレーニングされたモデルを自動的に検証し、古いモデルと比較します。 精度が向上したかどうかを判断し、 向上した場合は、このモデルを次の手順で使用できるように、モデル レジストリに登録できます。 新しいモデルのパフォーマンスがより低い場合、データ サイエンティストにアラートを出して、新しくトレーニングされたモデルを調査したり破棄したりすることができます。

### <a name="deploy-the-model"></a>モデルをデプロイする

デプロイ手順で、モデルを Web アプリケーション用の API サービスとしてデプロイします。 このアプローチでは、モデルをアプリケーションから独立してスケーリングし、更新することができます。 または、モデルを 1 回または定期的に使用して新しいデータ ポイントの予測を計算するバッチ スコアリングに使用することもできます。 これは、大量のデータを非同期的に処理する必要がある場合に便利です。 展開モデルの詳細については、「[展開時の機械学習推論](./ml-deployment-inference.md)」のページを参照してください。

### <a name="monitor-the-model"></a>モデルを監視する

2 つの主な理由から、モデルを監視する必要があります。 まず、モデルを監視することで、技術的に機能している (予測を生成できるなど) ことを確認することができます。 これは、組織のアプリケーションがモデルに依存していて、リアルタイムで使用している場合に重要です。 モデルを監視することは、有用な予測が継続的に生成されているかどうかを評価するのにも役立ちます。 これは、モデルのトレーニングに使用されるデータが、予測フェーズ中にモデルに送信されたデータと大幅に異なる場合など、データ ドリフトが発生した場合には役に立たないことがあります。 たとえば、若い人向けに製品を勧めるようトレーニングされたモデルでは、異なる年齢層の人に製品を勧めるときに望ましくない結果が生じる可能性があります。 モデルのデータ ドリフトを監視することで、このような種類のミスマッチを検出し、機械学習エンジニアにアラートを出し、より関連性の高い、または新しいデータを用いてモデルを自動的に再トレーニングすることができます。

### <a name="how-to-monitor-models"></a>モデルを監視する方法

データ ドリフト、季節性、またはパフォーマンスを向上させるためにチューニングされた新しいアーキテクチャは、いずれも時間の経過とともにモデルのパフォーマンスを低下させる原因となるため、モデルを継続的に展開するプロセスを確立することが重要です。 いくつかのベスト プラクティスを次に示します。

- **当事者意識:** パフォーマンスを積極的に管理するには、モデルのパフォーマンス監視プロセスに担当者を割り当てる必要があります。

- **リリース パイプライン:** まず、[Azure DevOps](/azure/devops/user-guide/what-is-azure-devops) でリリース パイプラインを設定し、モデル レジストリにトリガーを設定します。 新しいモデルがレジストリに登録されると、リリース パイプラインがトリガーとなり、配置プロセスが有効になります。

## <a name="prerequisites-for-retraining-models"></a>モデルの再トレーニングの前提条件

[運用環境のモデルからデータを収集する](/azure/machine-learning/how-to-enable-data-collection)ことは、継続的インテグレーションや継続的開発フレームワークでモデルを再トレーニングするための前提条件の 1 つであり、このプロセスではスコアリング要求からの入力データが使用されます。 この機能は現在、最小限の書式設定と操作で JSON として解析できる表形式のデータに限定されており、ビデオ、オーディオ、画像は除外されています。 この機能は、Azure Kubernetes Service (AKS) のモデルで使用できます。 収集したデータは、Azure BLOB に格納されます。

モデルの再トレーニングを準備するには:

1. **収集された入力データのデータ ドリフトを監視します。** 監視プロセスを設定するには、実稼働データからタイム スタンプを抽出する必要があります。 これは、実稼働データとベースライン データ (モデルの構築に使用されたトレーニング データ) を比較するために必要です。 データ ドリフトの監視には、Azure Monitor Application Insights を使用することをお勧めします。 この機能には、電子メール、SMS テキスト、プッシュ、Azure Functions などのアクションをトリガーできる[アラート](/azure/machine-learning/how-to-monitor-datasets#metrics-alerts-and-events)が備わっています。 データをログに記録するには、Application Insights を[有効](/azure/machine-learning/how-to-enable-app-insights#configure-logging-with-azure-machine-learning-studio)にする必要があります。

1. **収集したデータを分析します。** 必ず[運用環境のモデルからデータを収集](/azure/machine-learning/how-to-enable-data-collection)し、その結果をモデル スコアリング スクリプトに含めます。 モデル スコアリングに使用されたすべての特徴を収集します。これにより、すべての必要な特徴が存在し、トレーニング データとして使用できるようになります。

1. **収集したデータを使用して再トレーニングすることが必要かどうかを判断します。** データ ドリフトの原因には、季節性に対するセンサーの問題、ユーザーの行動の変化、データ ソースに関連するデータ品質の問題など、多くが挙げられます。 モデルの再トレーニングは、すべてのケースで必要になるわけではないため、データ ドリフトの原因を調査して理解してから行うことをお勧めします。

1. **モデルの再トレーニングを行います。** モデルトレーニングは既に自動化されているので、このステップでは、現在のトレーニング ステップをトリガーします。 これは、データ ドリフトが検出された場合 (かつ、これがデータの問題に関連していない場合)や、データ エンジニアがデータセットの新しいバージョンを公開した場合に行います。 ユース ケースに応じて、これらのステップは完全に自動化することも、人間が監督することもできます。 たとえば、製品のレコメンデーションのような一部のユース ケースでは、将来的に自律的に実行される可能性がありますが、金融分野ではモデルの公平性や透明性などの標準を考慮し、新たにトレーニングされたモデルでは人間による承認が必要になります。

最初は、モデルのトレーニングと展開だけを自動化して、手動で実行される検証、監視、再トレーニングのステップは自動化しないのが一般的です。 最終的には、望ましい状態になるまで自動化のステップを進めることができます。 DevOps や機械学習運用は時間をかけて発展していく概念であり、組織はその進化を認識しておく必要があります。

## <a name="the-team-data-science-process-lifecycle"></a>Team Data Science Process ライフサイクル

Team Data Science Process (TDSP) には、データ サイエンス プロジェクトの開発を体系化するライフサイクルが用意されています。 ライフサイクルは、プロジェクトで通常 (多くの場合に繰り返し) 実行される主要なステージのアウトラインを示します。

- ビジネスの把握
- データの取得と理解
- モデリング
- デプロイ

TDSP ライフサイクルの各ステージの目標、タスク、ドキュメント アーティファクトについては、「[Team Data Science Process ライフサイクル](/azure/machine-learning/team-data-science-process/lifecycle)」で説明しています。

## <a name="the-roles-and-activities-within-machine-learning-operations"></a>機械学習運用における役割とアクティビティ

TDSP ライフサイクルにおける AI プロジェクトの主要な役割は、データ エンジニア、データ サイエンティスト、機械学習基盤エンジニアです。 プロジェクトの成功に不可欠なこれらの役割は、正確で再現性があり、スケーラブルかつ実稼働可能なソリューションに向けて協力していく必要があります。

[![機械学習の運用プロセスを示す図。](./media/mlops-process.png)](./media/mlops-process.png#lightbox)

- **データ エンジニア:** この役割は、データの取り込み、検証、クリーンアップを行います。 データの加工が終わると、カタログ化され、データ サイエンティストが利用できるようになります。 この段階では、重複データの探索と分析、外れ値の削除、欠損データの特定を行うことが重要です。 これらのアクティビティはパイプラインのステップで定義する必要があり、トレーニング パイプラインが前処理されるときに実行されます。 コアおよび生成された特徴には、一意の名前と特定の名前を割り当てる必要があります。

- **データ サイエンティスト (または AI エンジニア):** この役割は、トレーニング パイプライン プロセスを進め、モデルの評価を行います。 データ サイエンティストは、データ エンジニアからデータを受け取り、その中のパターンと関係を特定し、実験のための特徴を選択したり生成したりします。 特徴エンジニアリングは、堅実な一般化モデルを構築する上で重要な役割を果たすため、このフェーズを可能な限り徹底的に行うことが重要です。 さまざまなアルゴリズムとハイパーパラメーターを使用して、あらゆる実験を実行できます。 自動機械学習などの Azure ツールを使用すると、このタスクを自動化することができ、モデルのアンダーフィットやオーバーフィットにも役立ちます。 正常にトレーニングされたモデルは、その後モデル レジストリに登録されます。 モデルには一意で固有の名前を付け、追跡可能性のためにバージョン履歴を保持する必要があります。

- **機械学習基盤エンジニア:** この役割は、継続的インテグレーションと配信のためのエンドツーエンドのパイプラインを構築します。 これには、Docker イメージへのモデルのパッキング、モデルの検証とプロファイリング、利害関係者からの承認の待機、および AKS などのコンテナー オーケストレーション サービスへのモデルのデプロイが含まれます。 継続的インテグレーション中に様々なトリガーを設定し、モデルのコードによってトレーニング パイプラインとリリース パイプラインを後でトリガーすることができます。
